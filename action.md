준비 단계 (사용자 & main.py)
사용자님께서 터미널에 명령을 입력하면(--json-path와 --id 지정), main.py가 가장 먼저 실행됩니다.
main.py는 지정된 JSON 파일을 열고, id가 "1"인 항목을 찾습니다.
해당 항목에서 분석의 대상이 될 코드(code_before)와 파일 경로(filepath_before) 정보를 문자열로 꺼내서 변수에 저장합니다.
AI 팀 구성 (main.py)
main.py는 AutoGen 프레임워크를 이용해 가상의 AI 전문가 팀을 만듭니다. 각자 역할이 명확합니다.
User_Proxy: 사용자님의 대리인입니다. 작업을 지시하고, 최종 결과물을 승인하는 역할을 합니다.
Analyzer: 코드 분석 전문가입니다. 주어진 코드의 문제점을 파악합니다.
Patcher: 패치 개발 전문가입니다. 분석가의 보고서를 보고 실제 수정 코드(패치)를 만듭니다.
Validator: 품질 보증(QA) 전문가입니다. 패치가 적용된 코드가 문제가 없는지 검증합니다. (현재는 실제 빌드/테스트 없이 "성공"이라고 답하는 시뮬레이션 상태입니다.)
자율적인 작업 수행 (가장 중요한 부분)
User_Proxy가 그룹 채팅방에 첫 메시지를 보냅니다. 이 메시지에는 1단계에서 추출한 code_before와 filepath_before가 포함되어 있습니다. "Analyzer님, 이 파일 경로에 있는 이 코드를 분석해서 취약점을 찾아주세요." 와 같은 구체적인 지시를 내립니다.
채팅방의 관리자(Manager)는 이 메시지를 보고, 작업을 수행할 가장 적합한 전문가인 Analyzer 를 지목합니다.
Analyzer 가 코드를 분석하고 자신의 생각을 채팅방에 공유합니다. (방금 실행 결과에서 길게 출력된 부분이 바로 이 과정입니다.) Analyzer는 더 나은 해결책을 찾기 위해 스스로 여러 아이디어를 제시하고 개선하며 매우 깊이 있는 분석을 수행했습니다.
원래의 이상적인 흐름이라면, Analyzer가 분석을 마친 후 Patcher가 그 보고서를 받아 패치를 만들고, Validator가 검증하는 순서로 대화가 오가야 합니다.
만약 Validator가 "패치를 적용하니 빌드가 실패했습니다"라고 보고하면, 관리자는 다시 Patcher를 지목하여 "에러 로그를 참고해서 패치를 다시 만들어주세요"라고 지시하며 문제가 해결될 때까지 이 과정이 반복됩니다.
최종적으로 Validator가 "검증 성공!"을 외치면, User_Proxy가 최종 승인을 하고 전체 작업이 마무리됩니다.
방금 실행에서 Analyzer만 계속 이야기한 이유:
LLM(대규모 언어 모델)의 특성상, 주어진 프롬프트에 대해 한번에 완벽한 답을 내놓기보다 여러 번의 사고 과정을 거쳐 답변을 구체화하는 경향이 있습니다. 이번 실행에서는 Analyzer가 워낙 유능해서, 다른 에이전트에게 넘기기 전에 혼자서 가능한 모든 개선점을 찾아내고 보고하는 모습을 보여준 것입니다. 설정된 대화 횟수(20회)를 다 쓸 때까지 심층 분석을 한 것이죠. 이는 시스템이 의도대로 잘 동작하고 있다는 증거이기도 합니다.
궁금한 점이 또 있으신가요?